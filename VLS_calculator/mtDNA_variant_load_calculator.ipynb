{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i2GdmFImXB8a"
   },
   "source": [
    "# Instructions\n",
    "This notebook takes a Pathogenic scoring lookup table and calculates the variant load for all protein-encoding genes from raw fasta mtDNA files or a list of patient variants.\n",
    "\n",
    "Before uploading a lookup table ensure the mtDNA variant lookup table has the following three column headings: Position, Reference, Mutation, Pathogenicity_Score\n",
    "\n",
    "The position column corresponds to the reference mtDNA unaligned genome and the Mutation column contains all possible variants at each position.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_sqz_-4sYh2E"
   },
   "source": [
    "1. First run the cell below to import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": "form",
    "id": "jY4R4sQSVcM5"
   },
   "outputs": [],
   "source": [
    "#@title Load packages\n",
    "\n",
    "\n",
    "#%%capture\n",
    "#makes cell silent\n",
    "\n",
    "from IPython.display import clear_output\n",
    "#!sudo apt install clustalo\n",
    "#!curl -sL haplogrep.now.sh | bash\n",
    "#clear_output()\n",
    "#!pip install gradio==4.44.1 # make sure match with version used on server\n",
    "#!pip install Biopython\n",
    "#!pip install tqdm\n",
    "#clear_output()\n",
    "!conda env list # check conda is working\n",
    "!clustalo --version # check this is working\n",
    "from Bio import SeqIO, AlignIO\n",
    "from Bio.Align.Applications import ClustalwCommandline,ClustalOmegaCommandline  # , MuscleCommandline\n",
    "import os\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from Bio import pairwise2\n",
    "from Bio.pairwise2 import format_alignment\n",
    "import gradio as gr\n",
    "clear_output()\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from Bio.Align.Applications import ClustalOmegaCommandline\n",
    "import gradio as gr\n",
    "import re\n",
    "#!wget https://github.com/Iqbalwasim01/mtDNA/archive/refs/heads/main.zip\n",
    "#!unzip -o main.zip\n",
    "#clear_output()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8pHX0lwLYks6"
   },
   "source": [
    "2. Now run the cell below to load the user-friendly interface. The following file uploads will be required:\n",
    "\n",
    "\n",
    "*   Patient data: Either a FASTA or .txt file containing unaligned patient mtDNA genomes OR a .txt file containing patient variants.\n",
    "\n",
    "  *   If a FASTA file is provided for patient mtDNA genomes, upload a FASTA, .txt, or .gb file containing a mtDNA reference genome.\n",
    "\n",
    "*   A .csv file for pathogenic score lookup. Before uploading a lookup table ensure the mtDNA variant lookup table has the following four column headings: Position, Reference, Mutation, Pathogenicity_Score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0WAv6VEpFPh3",
    "outputId": "ea2da2ea-aae3-47e7-cb0c-17fcaf44688e"
   },
   "outputs": [],
   "source": [
    "#@title VLS calculator\n",
    "\n",
    "def Variant_load_calculation_haploexclude_all_characters(table, list_seq, list_var, reference_seq, Haplomarker_percentage, APOGEE_threshold, Haplomarker_total_count):\n",
    "    table = pd.read_csv(table.name)\n",
    "    reference_seq = list(SeqIO.parse(reference_seq.name, \"fasta\"))\n",
    "    list_seq = list(SeqIO.parse(list_seq.name, \"fasta\"))\n",
    "    haplovariants_table=pd.read_csv(\"mtDNA-main/Haplo_context.csv\")\n",
    "    haplovariants_table=haplovariants_table[(haplovariants_table['Percentage']>=Haplomarker_percentage) & (haplovariants_table['total']>=Haplomarker_total_count)] # subset halpovariants_table based variant frequency\n",
    "\n",
    "    table['Position'] = table['Position'].values - 1  # Adjust Position to match Python indexing\n",
    "    haplovariants_table['Position'] = haplovariants_table['Position'].values - 1\n",
    "\n",
    "    results_df = pd.DataFrame(columns=[\"Patient\", \"Variant Load Score\"])\n",
    "    for patient in tqdm(range(0, len(list_seq)), desc=\"Sifting through mutations per patient\"):\n",
    "        SeqIO.write(list_seq[patient], \"./unaligned_seq_patient.fasta\", \"fasta\") # write the aligned patient sequence to use later for halpocontext\n",
    "        Sequences = reference_seq + list_seq[patient:patient+1]\n",
    "        with open(\"./unaligned_seq.fasta\", \"w\") as unaligned_file:\n",
    "            SeqIO.write(Sequences, unaligned_file, \"fasta\")\n",
    "\n",
    "        clustalw_cline = ClustalOmegaCommandline(\"clustalo\", infile=\"./unaligned_seq.fasta\", outfile=\"aligned_seq.aln\", force=True)\n",
    "        clustalw_cline()\n",
    "\n",
    "        sequences = list(SeqIO.parse(\"aligned_seq.aln\", \"fasta\"))\n",
    "        list_seq_aligned = str(sequences[1].seq)\n",
    "        ref_aligned = str(sequences[0].seq)\n",
    "\n",
    "        new_positions = [aligned_position for aligned_position in range(0, len(ref_aligned)) if ref_aligned[aligned_position] != '-']\n",
    "\n",
    "        unaligned_ref_positions = list(range(0, 16569))\n",
    "        ref_to_aligned_positions = dict(zip(unaligned_ref_positions, new_positions))\n",
    "\n",
    "        haplovariants_table['Aligned_Positions'] = haplovariants_table['Position'].map(ref_to_aligned_positions) # need to also map the aligned positions to the haplocontext/variant table\n",
    "        haplovariants_table.set_index('Aligned_Positions', inplace=True)\n",
    "        table['Aligned_Positions'] = table['Position'].map(ref_to_aligned_positions)\n",
    "        table.set_index('Aligned_Positions', inplace=True)\n",
    "        Position = table.index.unique()\n",
    "\n",
    "\n",
    "        !./haplogrep classify --in \"unaligned_seq_patient.fasta\" --output \"results.txt\" --format fasta  --lineage 1 #--extend-report #--hetLevel 0.1\n",
    "        !grep \" \" \" results.dot > results.txt\n",
    "        df_hap=pd.read_csv(\"results.txt\",sep=\"\\t\").loc[:,\"Haplogroup\"]\n",
    "        Parent_haplo=[i for i in df_hap.values][0]\n",
    "        #print(f'{Parent_haplo}')\n",
    "\n",
    "        Variant_positions = []\n",
    "        patient_scores = []\n",
    "        for position in Position:\n",
    "            current_position_mutations = table.loc[position,:]\n",
    "            # this block of code subsets haplogroup marker rows with the best match to the patient haplogroup\n",
    "            prefixes = [Parent_haplo[:i] for i in range(1, len(Parent_haplo) + 1)] # create all possible haplonames left to right from current haplogroup\n",
    "            matching_rows = haplovariants_table[haplovariants_table['Haplogroup_marker'].apply(lambda x: any(x.startswith(prefix) for prefix in prefixes))].copy()\n",
    "            matching_rows.loc[:, 'char_length'] = matching_rows['Haplogroup_marker'].apply(len) # get length all haplomatches\n",
    "            Haplo_max=matching_rows['char_length'].max() # find the best match i.e. most character match and by one of the prefixes\n",
    "            matching_rows = matching_rows[(matching_rows['char_length']==Haplo_max) &  (matching_rows['Haplogroup_marker'].isin(prefixes))] # subset the haplogroup with the greatest character length and must match one of the original prefixes\n",
    "            current_pos_haplo_mutations = matching_rows[matching_rows.index == position] # match position to get final haplomarker\n",
    "            if isinstance(current_position_mutations, pd.Series):\n",
    "                current_position_mutations = current_position_mutations.to_frame().T\n",
    "            base = list_seq_aligned[position]\n",
    "            Score = current_position_mutations[current_position_mutations['Mutation'] == base]['Pathogenicity_Score']\n",
    "            unaligned_position = current_position_mutations[current_position_mutations['Mutation'] == base]['Position'] + 1\n",
    "            Reference_base = current_position_mutations[current_position_mutations['Mutation'] == base]['Reference']\n",
    "            if (base in current_pos_haplo_mutations['Mutation'].values):\n",
    "                patient_scores.append(np.nan)\n",
    "                Variant_positions.append(f\"Excluded from score as native to haplogroup: \\n{Reference_base.iloc[0]}{unaligned_position.iloc[0]}{base}\")\n",
    "            elif(Score.empty or Score.iloc[0] < APOGEE_threshold):\n",
    "                patient_scores.append(np.nan)\n",
    "            else:\n",
    "                patient_scores.append(Score.iloc[0])\n",
    "                Variant_positions.append(f\"{Reference_base.iloc[0]}{unaligned_position.iloc[0]}{base}\")\n",
    "\n",
    "        #print(f'{matching_rows.head(n=3)}')\n",
    "\n",
    "        # NEED TO FIX THIS TO EXTRACT HVARIANTS AS NOW CHANGED FORMAT AFTER USING UNALIGNED FASTA!!!!\n",
    "        Variants_array = np.asarray(Variant_positions + [\"NA\"] * (100 - len(Variant_positions)))\n",
    "        Variants_df = pd.DataFrame([Variants_array], columns=[f'Pathogenic_Variant{i}' for i in range(0, 100)])\n",
    "        new_row = pd.DataFrame([[f\"Patient {str(sequences[1].id)}\", np.nansum(patient_scores)]], columns=[\"Patient\", \"Variant Load Score\"])\n",
    "        new_row = pd.concat([new_row,df_hap,Variants_df], axis=1)\n",
    "        results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "        yield results_df\n",
    "\n",
    "\n",
    "\n",
    "def Variant_load_calculation(table, list_seq, list_var, reference_seq, Haplomarker_percentage, APOGEE_threshold, Haplomarker_total_count):\n",
    "    table = pd.read_csv(table.name)\n",
    "    reference_seq = list(SeqIO.parse(reference_seq.name, \"fasta\"))\n",
    "    list_seq = list(SeqIO.parse(list_seq.name, \"fasta\"))\n",
    "\n",
    "    table['Position'] = table['Position'].values - 1  # Adjust Position to match Python indexing\n",
    "\n",
    "    results_df = pd.DataFrame(columns=[\"Patient\", \"Variant Load Score\"])\n",
    "    for patient in tqdm(range(0, len(list_seq)), desc=\"Sifting through mutations per patient\"):\n",
    "        SeqIO.write(list_seq[patient], \"./unaligned_seq_patient.fasta\", \"fasta\") # write the aligned patient sequence to use later for halpocontext\n",
    "        Sequences = reference_seq + list_seq[patient:patient + 1]\n",
    "        with open(\"./unaligned_seq.fasta\", \"w\") as unaligned_file:\n",
    "            SeqIO.write(Sequences, unaligned_file, \"fasta\")\n",
    "\n",
    "        clustalw_cline = ClustalOmegaCommandline(\"clustalo\", infile=\"./unaligned_seq.fasta\", outfile=\"aligned_seq.aln\", force=True)\n",
    "        clustalw_cline()\n",
    "\n",
    "        sequences = list(SeqIO.parse(\"aligned_seq.aln\", \"fasta\"))\n",
    "        list_seq_aligned = str(sequences[1].seq)\n",
    "        ref_aligned = str(sequences[0].seq)\n",
    "\n",
    "        new_positions = [aligned_position for aligned_position in range(0, len(ref_aligned)) if ref_aligned[aligned_position] != '-']\n",
    "\n",
    "        unaligned_ref_positions = list(range(0, 16569))\n",
    "        ref_to_aligned_positions = dict(zip(unaligned_ref_positions, new_positions))\n",
    "\n",
    "        table['Aligned_Positions'] = table['Position'].map(ref_to_aligned_positions)\n",
    "        table.set_index('Aligned_Positions', inplace=True)\n",
    "        Position = table.index.unique()\n",
    "\n",
    "        Variant_positions = []\n",
    "        patient_scores = []\n",
    "        for position in Position:\n",
    "            current_position_mutations = table.loc[position,:]\n",
    "            if isinstance(current_position_mutations, pd.Series):\n",
    "                current_position_mutations = current_position_mutations.to_frame().T\n",
    "            base = list_seq_aligned[position]\n",
    "            Score = current_position_mutations[current_position_mutations['Mutation'] == base]['Pathogenicity_Score']\n",
    "            unaligned_position = current_position_mutations[current_position_mutations['Mutation'] == base]['Position'] + 1\n",
    "            Reference_base = current_position_mutations[current_position_mutations['Mutation'] == base]['Reference']\n",
    "            if Score.empty or Score.iloc[0] < APOGEE_threshold:\n",
    "                patient_scores.append(np.nan)\n",
    "            else:\n",
    "                patient_scores.append(Score.iloc[0])\n",
    "                Variant_positions.append(f\"{Reference_base.iloc[0]}{unaligned_position.iloc[0]}{base}\")\n",
    "\n",
    "        # NEED TO FIX THIS TO EXTRACT HVARIANTS AS NOW CHANGED FORMAT AFTER USING UNALIGNED FASTA!!!!\n",
    "        !./haplogrep classify --in \"unaligned_seq_patient.fasta\" --output \"results.txt\" --format fasta  --lineage 1 #--extend-report #--hetLevel 0.1\n",
    "        !grep \" \" \" results.dot > results.txt\n",
    "        df_hap=pd.read_csv(\"results.txt\",sep=\"\\t\").loc[:,\"Haplogroup\"]\n",
    "        Variants_array = np.asarray(Variant_positions + [\"NA\"] * (100 - len(Variant_positions)))\n",
    "        Variants_df = pd.DataFrame([Variants_array], columns=[f'Pathogenic_Variant{i}' for i in range(0, 100)])\n",
    "        new_row = pd.DataFrame([[f\"Patient {str(sequences[1].id)}\", np.nansum(patient_scores)]], columns=[\"Patient\", \"Variant Load Score\"])\n",
    "        new_row = pd.concat([new_row,df_hap,Variants_df], axis=1)\n",
    "        results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "        yield results_df\n",
    "\n",
    "\n",
    "\n",
    "def Variant_load_calculation_variant(table, list_seq, list_var, reference_seq, Haplomarker_percentage, APOGEE_threshold, Haplomarker_total_count):\n",
    "\n",
    "    #Read in input\n",
    "    table = pd.read_csv(table)\n",
    "    list_var = open(list_var, \"r\")\n",
    "    patient_list = list_var.read() #CHANGE TO READLINE\n",
    "    patient_list = patient_list.split('\\n')\n",
    "\n",
    "    table['Position'] = table['Position'].values - 1  # Adjust Position to match Python indexing\n",
    "\n",
    "    results_df = pd.DataFrame(columns=[\"Patient\", \"Variant Load Score\"])\n",
    "\n",
    "\n",
    "    for patient in range(0, len(patient_list) -1):  #for each patient\n",
    "\n",
    "        patient = str(patient_list[patient])\n",
    "        pat_variants = patient.split(\";\") #splits patient variants by ;\n",
    "        pat_variants = [i.replace(' ','') for i in pat_variants] #removes white spaces\n",
    "        id = pat_variants[0] #get patient ID\n",
    "        pat_variants = pat_variants[1:len(pat_variants)] #takes variants by excluding first element, SHOULD CHANGE TO AVOID ERRORS\n",
    "\n",
    "\n",
    "        Variant_positions = []\n",
    "        patient_scores = []\n",
    "\n",
    "        #Get haplotype\n",
    "\n",
    "        haplo_input = [id, \"1-16569\", \"?\"] + [i for i in pat_variants if '-' not in i] #makes input for haplogrep, removes variants with mutation as '-'\n",
    "        with open(\"hsd.txt\", \"w\") as f:\n",
    "           f.write(\"ID\\tRange\\tHaplogroup\\tPolymorphisms\\n\")\n",
    "           f.write(\"\\t\".join(haplo_input))\n",
    "        f.close()\n",
    "\n",
    "        !./haplogrep classify --in \"hsd.txt\" --output \"results.txt\" --format hsd --lineage 1 > /dev/null 2>&1 #--extend-report #--hetLevel 0.1\n",
    "        df_hap=pd.read_csv(\"results.txt\",sep=\"\\t\").loc[:,\"Haplogroup\"]\n",
    "\n",
    "\n",
    "        for variant in pat_variants: #for each variant\n",
    "            variant = [x for x in re.split(r'([0-9]+)', variant) if x] #splits by numbers and letters, removing empty elements\n",
    "\n",
    "            #get position and base\n",
    "\n",
    "            if 'm.' in variant[0]: #if new format is used, MAY HAVE TO ADD EXTRA LINES IF BASE SEQ IS NOT ALWAYS THERE\n",
    "                position = variant[1]\n",
    "                base = variant[2][0]\n",
    "            else: #if old format used\n",
    "                if bool(re.search(\"^[A-Z]\" , variant[0])): #check if format contains base sequence\n",
    "                    position = variant[1]\n",
    "                    base = variant[0]\n",
    "                else:\n",
    "                    position = variant[0]\n",
    "                    base = None\n",
    "\n",
    "            #last letter = mutation (within indent x2)\n",
    "\n",
    "            mutation = variant[-1][-1]\n",
    "\n",
    "            #get info from lookup table (Pathogenicity score, and base if not included in input) using position and mutation\n",
    "\n",
    "            try:\n",
    "                score = table[(table['Position'] == (int(position) -1)) & (table['Mutation'] == mutation) ]['Pathogenicity_Score'].values[0] #map position to position of ref sequence\n",
    "            except IndexError: #if mutation is not within lookup table, skip to next variant\n",
    "                continue\n",
    "\n",
    "\n",
    "            if base is None:  #add base info if missing\n",
    "                base = table[(table['Position'] == (int(position) -1)) & (table['Mutation'] == mutation) ]['Reference'].values[0]\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "\n",
    "            # filtering\n",
    "\n",
    "            if score >= APOGEE_threshold: #skip variant if below cutoff threshold\n",
    "                patient_scores.append(score)\n",
    "                Variant_positions.append(f\"{base}{position}{mutation}\")\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "\n",
    "            #calculate VLS like Wasim (per patient)\n",
    "\n",
    "        Variants_array = np.asarray(Variant_positions + [\"NA\"] * (100 - len(Variant_positions)))\n",
    "        Variants_df = pd.DataFrame([Variants_array], columns=[f'Pathogenic_Variant{i}' for i in range(0, 100)])\n",
    "        new_row = pd.DataFrame([[f\"{id}\", np.nansum(patient_scores)]], columns=[\"Patient\", \"Variant Load Score\"])\n",
    "        new_row = pd.concat([new_row,df_hap,Variants_df], axis=1)\n",
    "        results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "        #!rm results.dot results.txt hsd.txt #remove haplogrep files as it seems to cause issues if left there\n",
    "\n",
    "        yield results_df\n",
    "\n",
    "\n",
    "def Variant_load_calculation_variant_haploexclude(table, list_seq, list_var, reference_seq, Haplomarker_percentage, APOGEE_threshold, Haplomarker_total_count):\n",
    "\n",
    "    #Read in input\n",
    "    table = pd.read_csv(table)\n",
    "    list_var = open(list_var, \"r\")\n",
    "    patient_list = list_var.read() #CHANGE TO READLINE\n",
    "    patient_list = patient_list.split('\\n')\n",
    "    haplovariants_table=pd.read_csv(\"mtDNA-main/Haplo_context.csv\")\n",
    "    haplovariants_table=haplovariants_table[(haplovariants_table['Percentage']>=Haplomarker_percentage) & (haplovariants_table['total']>=Haplomarker_total_count)] # subset halpovariants_table based variant frequency\n",
    "\n",
    "\n",
    "    table['Position'] = table['Position'].values - 1  # Adjust Position to match Python indexing\n",
    "\n",
    "    results_df = pd.DataFrame(columns=[\"Patient\", \"Variant Load Score\"])\n",
    "\n",
    "\n",
    "    for patient in range(0, len(patient_list)-1):  #for each patient\n",
    "\n",
    "        patient = str(patient_list[patient])\n",
    "        pat_variants = patient.split(\";\") #splits patient variants by ;\n",
    "        pat_variants = [i.replace(' ','') for i in pat_variants] #removes white spaces\n",
    "        id = pat_variants[0] #get patient ID\n",
    "        pat_variants = pat_variants[1:len(pat_variants)] #takes variants by excluding first element, SHOULD CHANGE TO AVOID ERRORS\n",
    "\n",
    "\n",
    "        Variant_positions = []\n",
    "        patient_scores = []\n",
    "\n",
    "        #Get haplotype\n",
    "\n",
    "        haplo_input = [id, \"1-16569\", \"?\"] + [i for i in pat_variants if '-' not in i] #makes input for haplogrep, removes variants with mutation as '-'\n",
    "        with open(\"hsd.txt\", \"w\") as f:\n",
    "           f.write(\"ID\\tRange\\tHaplogroup\\tPolymorphisms\\n\")\n",
    "           f.write(\"\\t\".join(haplo_input))\n",
    "        f.close()\n",
    "\n",
    "        !./haplogrep classify --in \"hsd.txt\" --output \"results.txt\" --format hsd --lineage 1 > /dev/null 2>&1 #--extend-report #--hetLevel 0.1\n",
    "        df_hap=pd.read_csv(\"results.txt\",sep=\"\\t\").loc[:,\"Haplogroup\"]\n",
    "\n",
    "        for variant in pat_variants: #for each variant\n",
    "            variant = [x for x in re.split(r'([0-9]+)', variant) if x] #splits by numbers and letters, removing empty elements\n",
    "\n",
    "            #get position and base\n",
    "\n",
    "            if 'm.' in variant[0]: #if new format is used, MAY HAVE TO ADD EXTRA LINES IF BASE SEQ IS NOT ALWAYS THERE\n",
    "                position = variant[1]\n",
    "                base = variant[2][0]\n",
    "            else: #if old format used\n",
    "                if bool(re.search(\"^[A-Z]\" , variant[0])): #check if format contains base sequence\n",
    "                    position = variant[1]\n",
    "                    base = variant[0]\n",
    "                else:\n",
    "                    position = variant[0]\n",
    "                    base = None\n",
    "\n",
    "            #last letter = mutation (within indent x2)\n",
    "\n",
    "            mutation = variant[-1][-1]\n",
    "\n",
    "            #get info from lookup table (Pathogenicity score, and base if not included in input) using position and mutation\n",
    "\n",
    "            try:\n",
    "                score = table[(table['Position'] == (int(position) -1)) & (table['Mutation'] == mutation) ]['Pathogenicity_Score'].values[0] #map position to position of ref sequence\n",
    "            except IndexError: #if mutation is not within lookup table, skip to next variant\n",
    "                continue\n",
    "\n",
    "            if base is None: #add base info if missing\n",
    "                base = table[(table['Position'] == (int(position) -1)) & (table['Mutation'] == mutation) ]['Reference'].values[0]\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "\n",
    "            #get haplotype mutations for filtering\n",
    "\n",
    "            Parent_haplo=[i for i in df_hap.values][0]\n",
    "\n",
    "            prefixes = [Parent_haplo[:i] for i in range(1, len(Parent_haplo) + 1)] # create all possible haplonames left to right from current haplogroup\n",
    "            matching_rows = haplovariants_table[haplovariants_table['Haplogroup_marker'].apply(lambda x: any(x.startswith(prefix) for prefix in prefixes))].copy()\n",
    "            matching_rows.loc[:, 'char_length'] = matching_rows['Haplogroup_marker'].apply(len) # get length all haplomatches\n",
    "            Haplo_max=matching_rows['char_length'].max() # find the best match i.e. most character match and by one of the prefixes\n",
    "            matching_rows = matching_rows[(matching_rows['char_length']==Haplo_max) &  (matching_rows['Haplogroup_marker'].isin(prefixes))] # subset the haplogroup with the greatest character length and must match one of the original prefixes\n",
    "            current_pos_haplo_mutations = matching_rows[matching_rows['Position'] == int(position)] # match position to get final haplomarker\n",
    "\n",
    "\n",
    "            #filtering\n",
    "\n",
    "\n",
    "            if score >= APOGEE_threshold: #skip variant if below cutoff threshold\n",
    "                pass\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            if (mutation in current_pos_haplo_mutations['Mutation'].values):\n",
    "                Variant_positions.append(f\"Excluded from score as native to haplogroup: \\n{base}{position}{mutation}\")\n",
    "            else:\n",
    "                patient_scores.append(score)\n",
    "                Variant_positions.append(f\"{base}{position}{mutation}\")\n",
    "\n",
    "\n",
    "\n",
    "            #calculate VLS like Wasim (per patient)\n",
    "\n",
    "        Variants_array = np.asarray(Variant_positions + [\"NA\"] * (100 - len(Variant_positions)))\n",
    "        Variants_df = pd.DataFrame([Variants_array], columns=[f'Pathogenic_Variant{i}' for i in range(0, 100)])\n",
    "        new_row = pd.DataFrame([[f\"{id}\", np.nansum(patient_scores)]], columns=[\"Patient\", \"Variant Load Score\"])\n",
    "        new_row = pd.concat([new_row,df_hap,Variants_df], axis=1)\n",
    "        results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "        #!rm results.dot results.txt hsd.txt #remove haplogrep files as it seems to cause issues if left there\n",
    "\n",
    "        yield results_df\n",
    "\n",
    "\n",
    "def save_results(results):\n",
    "    results.to_csv('./results.csv', index=False)\n",
    "    return './results.csv'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create the Gradio interface\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#---------------------------\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# STEP 2 : We create the gradio user friendly interface below.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#---------------------------\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m gr\u001b[38;5;241m.\u001b[39mBlocks() \u001b[38;5;28;01mas\u001b[39;00m interface: \u001b[38;5;66;03m# Whenever you create a gradio interface you start with gr.blocks() which essentially means start a fresh blank page\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     gr\u001b[38;5;241m.\u001b[39mMarkdown(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m## Mitochondrial Variant Load Calculator\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m     gr\u001b[38;5;241m.\u001b[39mMarkdown(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Please upload all three required files\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gr' is not defined"
     ]
    }
   ],
   "source": [
    "# Create the Gradio interface\n",
    "\n",
    "#---------------------------\n",
    "# STEP 2 : We create the gradio user friendly interface below.\n",
    "#---------------------------\n",
    "\n",
    "with gr.Blocks() as interface: # Whenever you create a gradio interface you start with gr.blocks() which essentially means start a fresh blank page\n",
    "    gr.Markdown(\"## Mitochondrial Variant Load Calculator\")\n",
    "    gr.Markdown(\"# Please upload all three required files\")\n",
    "\n",
    "    with gr.Row(): # gr.row allows you to start placing objects on a fresh row or on the same row.\n",
    "        table = gr.File(label=\"Upload Look-up Table (CSV)\", file_types=[\"csv\"])\n",
    "        reference_seq = gr.File(label=\"Upload Reference Sequence (GenBank)\", file_types=[\"fasta\", \"gb\", \"txt\"])\n",
    "        list_seq = gr.File(label=\"Upload Variant Sequences (FASTA)\", file_types=[\"fasta\", \"txt\"])\n",
    "        list_var = gr.File(label=\"Upload Variant List\", file_types=[\"txt\"])\n",
    "\n",
    "    with gr.Row():\n",
    "        APOGEE_threshold = gr.Slider(label=\"Exclude scores by specifying minimum pathogenicity score threshold\",step=0.01,minimum=0.00,maximum=1.00)\n",
    "        haploexclude_full = gr.Checkbox(label=\"Exclude haplogroup markers from score based on haplogroup (e.g. L3f)\")\n",
    "        Haplomarker_total_count = gr.Slider(label=\"Filter halpogroup exclusion table by minimum clade size (n)\",step=1,minimum=0,maximum=200)\n",
    "        Haplomarker_percentage = gr.Slider(label=\"Filter halpogroup exclusion table by percentage clade with variant (%)\",step=1)\n",
    "\n",
    "    calculate_button = gr.Button(\"Calculate Variant Load\") # To add a button with a name you simply use gr.Button#()\n",
    "\n",
    "    output = gr.DataFrame(headers=[\"Patient\", \"Variant Load Score\", \"Haplogroup\", # If you want to have a dataframe on your interface you need to specify gr.DataFrame() function\n",
    "             'Pathogenic_Variant0', 'Pathogenic_Variant1', 'Pathogenic_Variant2', # You need to specify the same heading names and column numbers as the dataframe output from your function i.e. Variant_load_calculation or Variant_load_calculation_haploexclude_all_characters\n",
    "             'Pathogenic_Variant3', 'Pathogenic_Variant4', 'Pathogenic_Variant5',\n",
    "             'Pathogenic_Variant6', 'Pathogenic_Variant7', 'Pathogenic_Variant8',\n",
    "             'Pathogenic_Variant9', 'Pathogenic_Variant10', 'Pathogenic_Variant11',\n",
    "             'Pathogenic_Variant12', 'Pathogenic_Variant13', 'Pathogenic_Variant14'], label=\"Results\")\n",
    "\n",
    "    #download_button = gr.Button(\"Download CSV\")\n",
    "    download_file = gr.File(label=\"Downloaded Results\") # This allows you to add a button to download the results\n",
    "                                                        # If you want to use the gr.File() to download rather than upload files you simply asign a label name without a file_types=[]\n",
    "\n",
    "    # This function below takes our raw functions and inputs and selects which version of the function we should use a) Variant_load_calculation_haploexclude_all_characters or b) the default function Variant_load_calculation\n",
    "    # When the function version has been selected the chosen function then is saved in another object called calc_function which is then used to take the same inputs and calculate variant load scores per patient\n",
    "    def calculate_variant_load(table, list_seq, list_var, reference_seq, Haplomarker_percentage, haploexclude_full, APOGEE_threshold, Haplomarker_total_count):\n",
    "        if list_seq:\n",
    "            if haploexclude_full:\n",
    "                calc_function = Variant_load_calculation_haploexclude_all_characters # this your original function version 2 selected if checkbox is ticked (i.e. haploexclude_full)\n",
    "            else:\n",
    "                calc_function = Variant_load_calculation # this your original function or default function if checkbox is unticked\n",
    "        if list_var:\n",
    "            if haploexclude_full:\n",
    "                calc_function = Variant_load_calculation_variant_haploexclude\n",
    "            else:\n",
    "                calc_function = Variant_load_calculation_variant\n",
    "        results_df = pd.DataFrame(columns=[\"Patient\", \"Variant Load Score\", \"Haplogroup\"] + [f'Pathogenic_Variant{i}' for i in range(20)])\n",
    "\n",
    "        # Whichever function is selected from the if else statement above will be used in the for loop below to retrieve results per patient\n",
    "        for result in calc_function(table, list_seq, list_var, reference_seq, Haplomarker_percentage, APOGEE_threshold, Haplomarker_total_count):\n",
    "            results_df = pd.concat([results_df, result], ignore_index=True)\n",
    "            results_df = results_df.drop_duplicates(keep=\"first\")\n",
    "            # Save results incrementally\n",
    "            save_results(results_df)\n",
    "\n",
    "            results_path = os.path.join(\"./\", 'results.csv')\n",
    "            yield results_df.drop_duplicates(keep=\"first\"), results_path\n",
    "\n",
    "    #  The above function within functions is then used in the button below and takes the original inputs and then provides the outputs as a downloadable file.\n",
    "    calculate_button.click(\n",
    "        fn=calculate_variant_load, # this is the final wrapper function to compute everything after a button click\n",
    "        inputs=[table, list_seq, list_var, reference_seq, Haplomarker_percentage, haploexclude_full, APOGEE_threshold, Haplomarker_total_count], # These are the inputs e.g. file uploads or slider values or checkbox selection\n",
    "        outputs=[output, download_file] # this is the final output produced by the wrapper function\n",
    "    )\n",
    "\n",
    "\n",
    "# Launch the app\n",
    "interface.launch(share=True,height=1100,debug=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
